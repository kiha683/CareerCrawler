{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ğŸ”¹ SOP 1ï¼šGoogle Custom Search API Application and Usage\n",
        "\n",
        "Google Custom Search API allows programmatic querying of Google search results and retrieving the top 10 pages of search results.\n",
        "\n",
        "##âœ… 1ï¸âƒ£Apply for Google Cloud API\n",
        "\n",
        "    Go to Google Cloud Console\n",
        "    Create a new project  \n",
        "        Click \"Create Project\"  \n",
        "        Enter a project name (e.g., GoogleSearchAPI)  \n",
        "        Select \"No organization\" for location  \n",
        "        Click \"Create\"  \n",
        "    Ensure you have selected the project  \n",
        "        Select the newly created project in the top-left corner  \n",
        "\n",
        "##âœ… 2ï¸âƒ£ Enable Google Custom Search API\n",
        "\n",
        "    Go to API Console : Custom Search API  \n",
        "    Click \"Enable\"  \n",
        "    Wait for the API to be enabled  \n",
        "\n",
        "##âœ… 3ï¸âƒ£ Create API Key\n",
        "\n",
        "    Go to \"APIs & Services\" â†’ \"Credentials\" click Credentials Management Page  \n",
        "    Click \"Create Credentials\" â†’ Select \"API Key\"  \n",
        "    Copy the API Key  \n",
        "    (Optional) Set API restrictions  \n",
        "        Application Restrictions â†’ Select \"None\"  \n",
        "        API Restrictions â†’ Select \"Google Custom Search API\"  \n",
        "    Click \"Save\"  \n",
        "\n",
        "##âœ… 4ï¸âƒ£ Create Google Custom Search Engine (CSE)\n",
        "\n",
        "    Go to Google CSE enter CSE Console  \n",
        "    Click \"Add\"  \n",
        "    \"Sites to search\" select *.google.com or \"Search the entire web\"  \n",
        "    Click \"Create\"  \n",
        "    Go to \"Control Panel\"  \n",
        "    Copy the \"Search Engine ID (CSE ID)\"  \n",
        "\n",
        "#ğŸ”¹ SOP 2ï¼šReddit API Application and Usage\n",
        "\n",
        "Reddit API allows you to query subreddit posts, user information, and even send posts and comments.\n",
        "\n",
        "##âœ… 1ï¸âƒ£ Apply for Reddit API\n",
        "\n",
        "    Go to Reddit Developer Platform  \n",
        "    Log in to your Reddit account  \n",
        "    Click \"Create App\"  \n",
        "    Fill in the app information  \n",
        "        App Type: Select \"script\"  \n",
        "        App Name: Enter an app name (e.g., RedditAPIApp)  \n",
        "        About URL: Can be left blank  \n",
        "        Redirect URL: Enter http://localhost:8080  \n",
        "        Permissions: Default is fine  \n",
        "    Click \"Create App\"  \n",
        "    Note down the Client ID & Client Secret  \n",
        "        Client ID: 14-character alphanumeric code below the app name  \n",
        "        Client Secret: The secret key on the right  "
      ],
      "metadata": {
        "id": "xY08lz6DaKMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downlod"
      ],
      "metadata": {
        "id": "Rw7DL5CUHmYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import requests\n",
        "# Used for sending HTTP requests to interact with APIs or websites\n",
        "\n",
        "import nest_asyncio\n",
        "# Resolves asyncio runtime issues in Jupyter Notebook, allowing async code to run properly in Notebook\n",
        "\n",
        "import asyncio\n",
        "# Provides asynchronous I/O support for writing non-blocking asynchronous code\n",
        "\n",
        "!pip install asyncpraw\n",
        "import asyncpraw\n",
        "# An asynchronous client for Reddit API, used for asynchronously fetching Reddit data\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "# Handles dates and times, used for time calculations and formatting\n",
        "\n",
        "nest_asyncio.apply()\n",
        "# Enables nest_asyncio to support asyncio's event loop in Jupyter Notebook"
      ],
      "metadata": {
        "id": "VNEw6BWdH38C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0ac114-0d66-4dbd-b7f6-cbae334623e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting asyncpraw\n",
            "  Downloading asyncpraw-7.8.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting aiofiles (from asyncpraw)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.11/dist-packages (from asyncpraw) (3.11.14)\n",
            "Collecting aiosqlite<=0.17.0 (from asyncpraw)\n",
            "  Downloading aiosqlite-0.17.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting asyncprawcore<3,>=2.4 (from asyncpraw)\n",
            "  Downloading asyncprawcore-2.4.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting update_checker>=0.18 (from asyncpraw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.18.3)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from update_checker>=0.18->asyncpraw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (2025.1.31)\n",
            "Downloading asyncpraw-7.8.1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.17.0-py3-none-any.whl (15 kB)\n",
            "Downloading asyncprawcore-2.4.0-py3-none-any.whl (19 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: aiosqlite, aiofiles, update_checker, asyncprawcore, asyncpraw\n",
            "Successfully installed aiofiles-24.1.0 aiosqlite-0.17.0 asyncpraw-7.8.1 asyncprawcore-2.4.0 update_checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#paste your api key"
      ],
      "metadata": {
        "id": "wgfBkdXaH7mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Google setting\n",
        "API_KEY = \"change to yours\"\n",
        "SEARCH_ENGINE_ID = \"change to yours\"\n",
        "\n",
        "\n",
        "#  Reddit API setting\n",
        "reddit = asyncpraw.Reddit(\n",
        "    client_id=\"change to yours\",\n",
        "    client_secret=\"change to yours\",\n",
        "    user_agent=\"RedditJobSearchBot/1.0\"\n",
        ")"
      ],
      "metadata": {
        "id": "3FuktywJIIbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Load all sheets from the Excel\n",
        "file_path = \"/content/2025QS.xlsx\"\n",
        "sheets = pd.read_excel(file_path, sheet_name=None)"
      ],
      "metadata": {
        "id": "iyLL-qknwAOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Extract sheets for Social Science and World Rankings\n",
        "df_social_science = sheets[\"Social Science\"]\n",
        "df_world_rankings = sheets[\"World Rankings\"]\n",
        "\n",
        "#  Normalize country names for consistency across data sources\n",
        "country_mapping = {\n",
        "    \"United States of America\": \"USA\", \"United States\": \"USA\",\n",
        "    \"United Kingdom\": \"UK\", \"China (Mainland)\": \"China\",\n",
        "    \"Taiwan\": \"Taiwan\", \"Russian Federation\": \"Russia\",\n",
        "    \"South Korea\": \"South Korea\", \"Republic of Korea\": \"South Korea\",\n",
        "    \"Hong Kong SAR\": \"Hong Kong\", \"Macau SAR\": \"Macau\"\n",
        "}\n",
        "df_social_science[\"location\"] = df_social_science[\"location\"].replace(country_mapping)\n",
        "df_world_rankings[\"location code\"] = df_world_rankings[\"location code\"].replace(country_mapping)\n",
        "\n",
        "#  Convert ranking columns to numeric and drop rows with missing rankings\n",
        "df_social_science[\"2025\"] = pd.to_numeric(df_social_science[\"2025\"], errors=\"coerce\")\n",
        "df_world_rankings[\"rank display\"] = pd.to_numeric(df_world_rankings[\"rank display\"], errors=\"coerce\")\n",
        "df_social_science.dropna(subset=[\"2025\"], inplace=True)\n",
        "df_world_rankings.dropna(subset=[\"rank display\"], inplace=True)\n",
        "\n",
        "#  Retrieve the top N universities in a given country\n",
        "def get_top_n_universities(df, country_col, rank_col, name_col, country, n):\n",
        "    df[country_col] = df[country_col].astype(str).str.strip()\n",
        "    country = country.strip().lower()\n",
        "    country_df = df[df[country_col].str.lower() == country]\n",
        "    if len(country_df) == 0:\n",
        "        return []\n",
        "    country_df = country_df.sort_values(by=rank_col, ascending=True).reset_index(drop=True)\n",
        "    return country_df.iloc[:n][name_col].tolist()\n"
      ],
      "metadata": {
        "id": "WUCNB0ytwqE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Use Google Search API to look for relevant research terms\n",
        "def search_google(query):\n",
        "    url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={API_KEY}&cx={SEARCH_ENGINE_ID}&num=5\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    results = []\n",
        "    for item in data.get(\"items\", []):\n",
        "        results.append((item[\"title\"], item[\"link\"]))\n",
        "    return results"
      ],
      "metadata": {
        "id": "Hheb_QIbw7pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Search across Reddit for internship/research opportunities\n",
        "async def search_reddit(universities, keywords):\n",
        "    four_months_ago = datetime.now() - timedelta(days=120)\n",
        "    print(\"\\nã€Searching Reddit postsã€‘\\n\")\n",
        "\n",
        "    results_found = 0\n",
        "    subreddit = await reddit.subreddit(\"all\")\n",
        "\n",
        "    for uni in universities:\n",
        "        for keyword in keywords:\n",
        "            query = f'\"{uni}\" {keyword}'\n",
        "            print(f\"\\nï¼š{query}\")\n",
        "\n",
        "            async for post in subreddit.search(query, limit=30, sort=\"new\"):\n",
        "                post_time = datetime.fromtimestamp(post.created_utc)\n",
        "\n",
        "                if post_time >= four_months_ago:\n",
        "                    print(f\"Title: {post.title}\")\n",
        "                    print(f\"Date: {post_time.strftime('%Y-%m-%d')}\")\n",
        "                    print(f\"Link: {post.url}\")\n",
        "                    print(f\"Subreddit: r/{post.subreddit}\")\n",
        "                    print(\"-\" * 50)\n",
        "                    results_found += 1\n",
        "\n",
        "    if results_found == 0:\n",
        "        print(\"No relevant Reddit posts found.\")"
      ],
      "metadata": {
        "id": "0d2Iob1nxCfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enter your target country and the number of top universities you want from the QS overall ranking(type 1) or QS sociall science ranking(type 2).\n",
        "For example, if you want the top 5 universities in China:\n",
        "First, enter 1 (for QS overall ranking), then enter China (you can also use USA, UK, Russia, Japan, Honkong, India, Taiwan, Korea etc.), then enter 5.\n",
        "You should see results like Tsinghua, Peking, Fudan, Jiaotong, and Zhejiang.\n",
        "If you enter 1, then Russia, then 2, you should get HSE and MSU (just as I dreamed)."
      ],
      "metadata": {
        "id": "iZsbP32UIM39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Main query function to fetch universities and trigger Google/Reddit searches\n",
        "def university_query():\n",
        "    print(\"è«‹é¸æ“‡æŸ¥è©¢é¡å‹ / è¯·é€‰æ‹©æŸ¥è¯¢ç±»å‹ /\\n ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„ / ì¡°íšŒ ìœ í˜• ì„ íƒ /\\n Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ñ‚Ğ¸Ğ¿ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° /\\n Choisissez le type de requÃªte / WÃ¤hlen Sie den Abfragetyp /\\n Please select the query type\")\n",
        "    ranking_type = input(\"(1: QSç¶œåˆæ’å World Ranking, 2: QSç¤¾æœƒç§‘å­¸æ’å Social Science Ranking): \").strip()\n",
        "\n",
        "    print(\"è«‹è¼¸å…¥è¦æŸ¥è©¢çš„åœ‹å®¶ / è¾“å…¥å›½å®¶ /\\n å›½ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ / êµ­ê°€ë¥¼ ì…ë ¥í•˜ì„¸ìš” /\\n Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ÑÑ‚Ñ€Ğ°Ğ½Ñƒ /\\n Entrez le pays / Geben Sie das Land ein /\\n Enter the country\")\n",
        "    country = input(\"ä¾‹å¦‚ e.g., USAã€UKã€Russia: \").strip()\n",
        "\n",
        "    print(\"è«‹è¼¸å…¥è©²åœ‹å‰å¹¾åå¤§å­¸ / è¾“å…¥è¯¥å›½å‰Nåå¤§å­¦ /\\n ä¸Šä½æ ¡ã‚’å…¥åŠ› / ìƒìœ„ ëŒ€í•™ ìˆ˜ ì…ë ¥ /\\n Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ğ²ÑƒĞ·Ğ¾Ğ² /\\n Entrez le nombre d'universitÃ©s / Geben Sie die Anzahl der Top-Unis ein /\\n Enter the top N universities:\")\n",
        "    n = input(\"æ•¸å­— only number: \").strip()\n",
        "\n",
        "    if not n.isdigit():\n",
        "        print(\"è«‹è¼¸å…¥æ­£ç¢ºæ•¸å­— / è¯·è¾“å…¥æ­£ç¡®çš„æ•°å­— /\\n æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ / ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš” /\\n Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ /\\n Entrez un nombre valide / Geben Sie eine gÃ¼ltige Zahl ein /\\n Please enter a valid number.\")\n",
        "        return\n",
        "\n",
        "    n = int(n)\n",
        "    if ranking_type == '1':\n",
        "        universities = get_top_n_universities(df_world_rankings, \"location code\", \"rank display\", \"institution\", country, n)\n",
        "    else:\n",
        "        universities = get_top_n_universities(df_social_science, \"location\", \"2025\", \"Institution\", country, n)\n",
        "\n",
        "    if not universities:\n",
        "        print(f\"æ‰¾ä¸åˆ° {country} çš„å­¸æ ¡ / æœªæ‰¾åˆ° {country} çš„å¤§å­¦ /\\n {country} ã®å¤§å­¦ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ / {country}ì˜ ëŒ€í•™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ /\\n Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ¸Ñ‚ĞµÑ‚Ñ‹ {country} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ /\\n Aucune universitÃ© trouvÃ©e pour {country} / Keine UniversitÃ¤t in {country} gefunden /\\n No universities found in {country}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n{country.upper()} å‰ {n} åå¤§å­¸ / Top {n} Universities in {country.upper()}:\")\n",
        "    for i, uni in enumerate(universities, 1):\n",
        "        print(f\"{i}. {uni}\")\n",
        "\n",
        "    search_keywords = [\n",
        "        \"summer research internship\", \"remote research assistant\", \"research scholarship\",\n",
        "    ]\n",
        "\n",
        "    print(\"\\næ­£åœ¨ä½¿ç”¨ Google æœå°‹ç ”ç©¶æ©Ÿæœƒ / æ­£åœ¨ç”¨Googleæœç´¢ç ”ç©¶æœºä¼š /\\n Googleã§ç ”ç©¶æ©Ÿä¼šã‚’æ¤œç´¢ä¸­ / Googleì„ ì‚¬ìš©í•˜ì—¬ ì—°êµ¬ ê¸°íšŒ ê²€ìƒ‰ ì¤‘ /\\n Ğ˜Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ² Google /\\n Recherche d'opportunitÃ©s de recherche via Google / Recherche Ã¼ber Google nach Forschungsangeboten /\\n Searching research opportunities using Google...\\n\")\n",
        "    for uni in universities:\n",
        "        print(f\"\\n{uni} çš„æœå°‹çµæœ / Search results for {uni}:\")\n",
        "        for keyword in search_keywords:\n",
        "            query = f\"{uni} {keyword}\"\n",
        "            results = search_google(query)\n",
        "            for title, link in results:\n",
        "                print(f\"{title}\\n{link}\")\n",
        "\n",
        "    print(\"\\næœå°‹ Reddit è²¼æ–‡ä¸­ / æ­£åœ¨æœç´¢Reddit /\\n Redditã®æŠ•ç¨¿ã‚’æ¤œç´¢ä¸­ / Reddit ê²Œì‹œë¬¼ ê²€ìƒ‰ ì¤‘ /\\n ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Reddit /\\n Recherche sur Reddit / Suche in Reddit /\\n Searching Reddit...\\n\")\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(search_reddit(universities, search_keywords))\n",
        "\n",
        "# âœ… Start the search process\n",
        "university_query()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej_PefuhxNSN",
        "outputId": "cefb7292-0f6f-49a6-8b86-339221e18d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è«‹é¸æ“‡æŸ¥è©¢é¡å‹ / è¯·é€‰æ‹©æŸ¥è¯¢ç±»å‹ /\n",
            " ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„ / ì¡°íšŒ ìœ í˜• ì„ íƒ /\n",
            " Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ñ‚Ğ¸Ğ¿ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° /\n",
            " Choisissez le type de requÃªte / WÃ¤hlen Sie den Abfragetyp /\n",
            " Please select the query type\n",
            "(1: QSç¶œåˆæ’å World Ranking, 2: QSç¤¾æœƒç§‘å­¸æ’å Social Science Ranking): 1\n",
            "è«‹è¼¸å…¥è¦æŸ¥è©¢çš„åœ‹å®¶ / è¾“å…¥å›½å®¶ /\n",
            " å›½ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ / êµ­ê°€ë¥¼ ì…ë ¥í•˜ì„¸ìš” /\n",
            " Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ÑÑ‚Ñ€Ğ°Ğ½Ñƒ /\n",
            " Entrez le pays / Geben Sie das Land ein /\n",
            " Enter the country\n",
            "ä¾‹å¦‚ e.g., USAã€UKã€Russia: usa\n",
            "è«‹è¼¸å…¥è©²åœ‹å‰å¹¾åå¤§å­¸ / è¾“å…¥è¯¥å›½å‰Nåå¤§å­¦ /\n",
            " ä¸Šä½æ ¡ã‚’å…¥åŠ› / ìƒìœ„ ëŒ€í•™ ìˆ˜ ì…ë ¥ /\n",
            " Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ»ÑƒÑ‡ÑˆĞ¸Ñ… Ğ²ÑƒĞ·Ğ¾Ğ² /\n",
            " Entrez le nombre d'universitÃ©s / Geben Sie die Anzahl der Top-Unis ein /\n",
            " Enter the top N universities:\n",
            "æ•¸å­— only number: 1\n",
            "\n",
            "USA å‰ 1 åå¤§å­¸ / Top 1 Universities in USA:\n",
            "1. Massachusetts Institute of Technology (MIT) \n",
            "\n",
            "æ­£åœ¨ä½¿ç”¨ Google æœå°‹ç ”ç©¶æ©Ÿæœƒ / æ­£åœ¨ç”¨Googleæœç´¢ç ”ç©¶æœºä¼š /\n",
            " Googleã§ç ”ç©¶æ©Ÿä¼šã‚’æ¤œç´¢ä¸­ / Googleì„ ì‚¬ìš©í•˜ì—¬ ì—°êµ¬ ê¸°íšŒ ê²€ìƒ‰ ì¤‘ /\n",
            " Ğ˜Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ñ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ² Google /\n",
            " Recherche d'opportunitÃ©s de recherche via Google / Recherche Ã¼ber Google nach Forschungsangeboten /\n",
            " Searching research opportunities using Google...\n",
            "\n",
            "\n",
            "Massachusetts Institute of Technology (MIT)  çš„æœå°‹çµæœ / Search results for Massachusetts Institute of Technology (MIT) :\n",
            "MIT Summer Research Program | MIT Office of Graduate Education\n",
            "https://oge.mit.edu/msrp/\n",
            "Summer Research Program | MIT Lincoln Laboratory\n",
            "https://www.ll.mit.edu/careers/student-opportunities/summer-research-program\n",
            "Summer research programs | Office of Graduate Education\n",
            "https://oge.mit.edu/graduate-admissions/applications/summer-research-programs/\n",
            "MIT UROP â€“ Undergraduate Research Opportunities Program\n",
            "https://urop.mit.edu/\n",
            "MITES Summer â€“ MITES\n",
            "https://mites.mit.edu/discover-mites/mites-summer/\n",
            "Jobs at MIT | MIT Human Resources\n",
            "https://hr.mit.edu/jobs\n",
            "Research Assistantships and Financial Support - Technology and ...\n",
            "https://tpp.mit.edu/academics/research-assistantships-and-financial-support/\n",
            "Departmental funding | MIT Student Financial Services\n",
            "https://sfs.mit.edu/graduate-students/funding-and-aid/departmental-funding/\n",
            "MIT UROP â€“ Undergraduate Research Opportunities Program\n",
            "https://urop.mit.edu/\n",
            "21 Mit Research Associate jobs in United States\n",
            "https://www.linkedin.com/jobs/mit-research-associate-jobs\n",
            "MIT Scholarships | MIT Student Financial Services\n",
            "https://sfs.mit.edu/undergraduate-students/types-of-aid/mit-scholarship/\n",
            "MIT Sea Grant: Home\n",
            "https://seagrant.mit.edu/\n",
            "Making MIT affordable | MIT Student Financial Services\n",
            "https://sfs.mit.edu/undergraduate-students/the-cost-of-attendance/making-mit-affordable/\n",
            "Massachusetts Institute of Technology - Wikipedia\n",
            "https://en.wikipedia.org/wiki/Massachusetts_Institute_of_Technology\n",
            "MIT THINK Scholars Program: Home\n",
            "https://think.mit.edu/\n",
            "\n",
            "æœå°‹ Reddit è²¼æ–‡ä¸­ / æ­£åœ¨æœç´¢Reddit /\n",
            " Redditã®æŠ•ç¨¿ã‚’æ¤œç´¢ä¸­ / Reddit ê²Œì‹œë¬¼ ê²€ìƒ‰ ì¤‘ /\n",
            " ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Reddit /\n",
            " Recherche sur Reddit / Suche in Reddit /\n",
            " Searching Reddit...\n",
            "\n",
            "\n",
            "ã€Searching Reddit postsã€‘\n",
            "\n",
            "\n",
            "ï¼š\"Massachusetts Institute of Technology (MIT) \" summer research internship\n",
            "\n",
            "ï¼š\"Massachusetts Institute of Technology (MIT) \" remote research assistant\n",
            "\n",
            "ï¼š\"Massachusetts Institute of Technology (MIT) \" research scholarship\n",
            "Title: I'm 15 and I'm planning to study in the us and I need guidance\n",
            "Date: 2024-12-13\n",
            "Link: https://www.reddit.com/r/ApplyingToCollege/comments/1hd6joa/im_15_and_im_planning_to_study_in_the_us_and_i/\n",
            "Subreddit: r/ApplyingToCollege\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hDNxGqOXydsD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}