{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üîπ SOP 1ÔºöGoogle Custom Search API Application and Usage\n",
        "\n",
        "Google Custom Search API allows programmatic querying of Google search results and retrieving the top 10 pages of search results.\n",
        "\n",
        "##‚úÖ 1Ô∏è‚É£Apply for Google Cloud API\n",
        "\n",
        "    Go to Google Cloud Console\n",
        "    Create a new project  \n",
        "        Click \"Create Project\"  \n",
        "        Enter a project name (e.g., GoogleSearchAPI)  \n",
        "        Select \"No organization\" for location  \n",
        "        Click \"Create\"  \n",
        "    Ensure you have selected the project  \n",
        "        Select the newly created project in the top-left corner  \n",
        "\n",
        "##‚úÖ 2Ô∏è‚É£ Enable Google Custom Search API\n",
        "\n",
        "    Go to API Console : Custom Search API  \n",
        "    Click \"Enable\"  \n",
        "    Wait for the API to be enabled  \n",
        "\n",
        "##‚úÖ 3Ô∏è‚É£ Create API Key\n",
        "\n",
        "    Go to \"APIs & Services\" ‚Üí \"Credentials\" click Credentials Management Page  \n",
        "    Click \"Create Credentials\" ‚Üí Select \"API Key\"  \n",
        "    Copy the API Key  \n",
        "    (Optional) Set API restrictions  \n",
        "        Application Restrictions ‚Üí Select \"None\"  \n",
        "        API Restrictions ‚Üí Select \"Google Custom Search API\"  \n",
        "    Click \"Save\"  \n",
        "\n",
        "##‚úÖ 4Ô∏è‚É£ Create Google Custom Search Engine (CSE)\n",
        "\n",
        "    Go to Google CSE enter CSE Console  \n",
        "    Click \"Add\"  \n",
        "    \"Sites to search\" select *.google.com or \"Search the entire web\"  \n",
        "    Click \"Create\"  \n",
        "    Go to \"Control Panel\"  \n",
        "    Copy the \"Search Engine ID (CSE ID)\"  \n",
        "\n",
        "#üîπ SOP 2ÔºöReddit API Application and Usage\n",
        "\n",
        "Reddit API allows you to query subreddit posts, user information, and even send posts and comments.\n",
        "\n",
        "##‚úÖ 1Ô∏è‚É£ Apply for Reddit API\n",
        "\n",
        "    Go to Reddit Developer Platform  \n",
        "    Log in to your Reddit account  \n",
        "    Click \"Create App\"  \n",
        "    Fill in the app information  \n",
        "        App Type: Select \"script\"  \n",
        "        App Name: Enter an app name (e.g., RedditAPIApp)  \n",
        "        About URL: Can be left blank  \n",
        "        Redirect URL: Enter http://localhost:8080  \n",
        "        Permissions: Default is fine  \n",
        "    Click \"Create App\"  \n",
        "    Note down the Client ID & Client Secret  \n",
        "        Client ID: 14-character alphanumeric code below the app name  \n",
        "        Client Secret: The secret key on the right  "
      ],
      "metadata": {
        "id": "xY08lz6DaKMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downlod"
      ],
      "metadata": {
        "id": "Rw7DL5CUHmYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import requests\n",
        "# Used for sending HTTP requests to interact with APIs or websites\n",
        "\n",
        "import nest_asyncio\n",
        "# Resolves asyncio runtime issues in Jupyter Notebook, allowing async code to run properly in Notebook\n",
        "\n",
        "import asyncio\n",
        "# Provides asynchronous I/O support for writing non-blocking asynchronous code\n",
        "\n",
        "!pip install asyncpraw\n",
        "import asyncpraw\n",
        "# An asynchronous client for Reddit API, used for asynchronously fetching Reddit data\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "# Handles dates and times, used for time calculations and formatting\n",
        "\n",
        "nest_asyncio.apply()\n",
        "# Enables nest_asyncio to support asyncio's event loop in Jupyter Notebook"
      ],
      "metadata": {
        "id": "VNEw6BWdH38C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0ac114-0d66-4dbd-b7f6-cbae334623e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting asyncpraw\n",
            "  Downloading asyncpraw-7.8.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting aiofiles (from asyncpraw)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.11/dist-packages (from asyncpraw) (3.11.14)\n",
            "Collecting aiosqlite<=0.17.0 (from asyncpraw)\n",
            "  Downloading aiosqlite-0.17.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting asyncprawcore<3,>=2.4 (from asyncpraw)\n",
            "  Downloading asyncprawcore-2.4.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting update_checker>=0.18 (from asyncpraw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.18.3)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from update_checker>=0.18->asyncpraw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (2025.1.31)\n",
            "Downloading asyncpraw-7.8.1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.17.0-py3-none-any.whl (15 kB)\n",
            "Downloading asyncprawcore-2.4.0-py3-none-any.whl (19 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: aiosqlite, aiofiles, update_checker, asyncprawcore, asyncpraw\n",
            "Successfully installed aiofiles-24.1.0 aiosqlite-0.17.0 asyncpraw-7.8.1 asyncprawcore-2.4.0 update_checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#paste your api key"
      ],
      "metadata": {
        "id": "wgfBkdXaH7mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Google setting\n",
        "API_KEY = \"change to yours\"\n",
        "SEARCH_ENGINE_ID = \"change to yours\"\n",
        "\n",
        "\n",
        "#  Reddit API setting\n",
        "reddit = asyncpraw.Reddit(\n",
        "    client_id=\"change to yours\",\n",
        "    client_secret=\"change to yours\",\n",
        "    user_agent=\"RedditJobSearchBot/1.0\"\n",
        ")"
      ],
      "metadata": {
        "id": "3FuktywJIIbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Load all sheets from the Excel\n",
        "file_path = \"/content/2025QS.xlsx\"\n",
        "sheets = pd.read_excel(file_path, sheet_name=None)"
      ],
      "metadata": {
        "id": "iyLL-qknwAOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Extract sheets for Social Science and World Rankings\n",
        "df_social_science = sheets[\"Social Science\"]\n",
        "df_world_rankings = sheets[\"World Rankings\"]\n",
        "\n",
        "#  Normalize country names for consistency across data sources\n",
        "country_mapping = {\n",
        "    \"United States of America\": \"USA\", \"United States\": \"USA\",\n",
        "    \"United Kingdom\": \"UK\", \"China (Mainland)\": \"China\",\n",
        "    \"Taiwan\": \"Taiwan\", \"Russian Federation\": \"Russia\",\n",
        "    \"South Korea\": \"South Korea\", \"Republic of Korea\": \"South Korea\",\n",
        "    \"Hong Kong SAR\": \"Hong Kong\", \"Macau SAR\": \"Macau\"\n",
        "}\n",
        "df_social_science[\"location\"] = df_social_science[\"location\"].replace(country_mapping)\n",
        "df_world_rankings[\"location code\"] = df_world_rankings[\"location code\"].replace(country_mapping)\n",
        "\n",
        "#  Convert ranking columns to numeric and drop rows with missing rankings\n",
        "df_social_science[\"2025\"] = pd.to_numeric(df_social_science[\"2025\"], errors=\"coerce\")\n",
        "df_world_rankings[\"rank display\"] = pd.to_numeric(df_world_rankings[\"rank display\"], errors=\"coerce\")\n",
        "df_social_science.dropna(subset=[\"2025\"], inplace=True)\n",
        "df_world_rankings.dropna(subset=[\"rank display\"], inplace=True)\n",
        "\n",
        "#  Retrieve the top N universities in a given country\n",
        "def get_top_n_universities(df, country_col, rank_col, name_col, country, n):\n",
        "    df[country_col] = df[country_col].astype(str).str.strip()\n",
        "    country = country.strip().lower()\n",
        "    country_df = df[df[country_col].str.lower() == country]\n",
        "    if len(country_df) == 0:\n",
        "        return []\n",
        "    country_df = country_df.sort_values(by=rank_col, ascending=True).reset_index(drop=True)\n",
        "    return country_df.iloc[:n][name_col].tolist()\n"
      ],
      "metadata": {
        "id": "WUCNB0ytwqE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Use Google Search API to look for relevant research terms\n",
        "def search_google(query):\n",
        "    url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={API_KEY}&cx={SEARCH_ENGINE_ID}&num=5\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    results = []\n",
        "    for item in data.get(\"items\", []):\n",
        "        results.append((item[\"title\"], item[\"link\"]))\n",
        "    return results"
      ],
      "metadata": {
        "id": "Hheb_QIbw7pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Search across Reddit for internship/research opportunities\n",
        "async def search_reddit(universities, keywords):\n",
        "    four_months_ago = datetime.now() - timedelta(days=120)\n",
        "    print(\"\\n„ÄêSearching Reddit posts„Äë\\n\")\n",
        "\n",
        "    results_found = 0\n",
        "    subreddit = await reddit.subreddit(\"all\")\n",
        "\n",
        "    for uni in universities:\n",
        "        for keyword in keywords:\n",
        "            query = f'\"{uni}\" {keyword}'\n",
        "            print(f\"\\nÔºö{query}\")\n",
        "\n",
        "            async for post in subreddit.search(query, limit=30, sort=\"new\"):\n",
        "                post_time = datetime.fromtimestamp(post.created_utc)\n",
        "\n",
        "                if post_time >= four_months_ago:\n",
        "                    print(f\"Title: {post.title}\")\n",
        "                    print(f\"Date: {post_time.strftime('%Y-%m-%d')}\")\n",
        "                    print(f\"Link: {post.url}\")\n",
        "                    print(f\"Subreddit: r/{post.subreddit}\")\n",
        "                    print(\"-\" * 50)\n",
        "                    results_found += 1\n",
        "\n",
        "    if results_found == 0:\n",
        "        print(\"No relevant Reddit posts found.\")"
      ],
      "metadata": {
        "id": "0d2Iob1nxCfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enter your target country and the number of top universities you want from the QS overall ranking(type 1) or QS sociall science ranking(type 2).\n",
        "For example, if you want the top 5 universities in China:\n",
        "First, enter 1 (for QS overall ranking), then enter China (you can also use USA, UK, Russia, Japan, Honkong, India, Taiwan, Korea etc.), then enter 5.\n",
        "You should see results like Tsinghua, Peking, Fudan, Jiaotong, and Zhejiang.\n",
        "If you enter 1, then Russia, then 2, you should get HSE and MSU (just as I dreamed)."
      ],
      "metadata": {
        "id": "iZsbP32UIM39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Main query function to fetch universities and trigger Google/Reddit searches\n",
        "def university_query():\n",
        "    print(\"Ë´ãÈÅ∏ÊìáÊü•Ë©¢È°ûÂûã / ËØ∑ÈÄâÊã©Êü•ËØ¢Á±ªÂûã /\\n Á®ÆÈ°û„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ / Ï°∞Ìöå Ïú†Ìòï ÏÑ†ÌÉù /\\n –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ /\\n Choisissez le type de requ√™te / W√§hlen Sie den Abfragetyp /\\n Please select the query type\")\n",
        "    ranking_type = input(\"(1: QSÁ∂úÂêàÊéíÂêç World Ranking, 2: QSÁ§æÊúÉÁßëÂ≠∏ÊéíÂêç Social Science Ranking): \").strip()\n",
        "\n",
        "    print(\"Ë´ãËº∏ÂÖ•Ë¶ÅÊü•Ë©¢ÁöÑÂúãÂÆ∂ / ËæìÂÖ•ÂõΩÂÆ∂ /\\n ÂõΩ„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ / Íµ≠Í∞ÄÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî /\\n –í–≤–µ–¥–∏—Ç–µ —Å—Ç—Ä–∞–Ω—É /\\n Entrez le pays / Geben Sie das Land ein /\\n Enter the country\")\n",
        "    country = input(\"‰æãÂ¶Ç e.g., USA„ÄÅUK„ÄÅRussia: \").strip()\n",
        "\n",
        "    print(\"Ë´ãËº∏ÂÖ•Ë©≤ÂúãÂâçÂπæÂêçÂ§ßÂ≠∏ / ËæìÂÖ•ËØ•ÂõΩÂâçNÂêçÂ§ßÂ≠¶ /\\n ‰∏ä‰ΩçÊ†°„ÇíÂÖ•Âäõ / ÏÉÅÏúÑ ÎåÄÌïô Ïàò ÏûÖÎ†• /\\n –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –ª—É—á—à–∏—Ö –≤—É–∑–æ–≤ /\\n Entrez le nombre d'universit√©s / Geben Sie die Anzahl der Top-Unis ein /\\n Enter the top N universities:\")\n",
        "    n = input(\"Êï∏Â≠ó only number: \").strip()\n",
        "\n",
        "    if not n.isdigit():\n",
        "        print(\"Ë´ãËº∏ÂÖ•Ê≠£Á¢∫Êï∏Â≠ó / ËØ∑ËæìÂÖ•Ê≠£Á°ÆÁöÑÊï∞Â≠ó /\\n Êï∞Â≠ó„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ / Ïà´ÏûêÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî /\\n –í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —á–∏—Å–ª–æ /\\n Entrez un nombre valide / Geben Sie eine g√ºltige Zahl ein /\\n Please enter a valid number.\")\n",
        "        return\n",
        "\n",
        "    n = int(n)\n",
        "    if ranking_type == '1':\n",
        "        universities = get_top_n_universities(df_world_rankings, \"location code\", \"rank display\", \"institution\", country, n)\n",
        "    else:\n",
        "        universities = get_top_n_universities(df_social_science, \"location\", \"2025\", \"Institution\", country, n)\n",
        "\n",
        "    if not universities:\n",
        "        print(f\"Êâæ‰∏çÂà∞ {country} ÁöÑÂ≠∏Ê†° / Êú™ÊâæÂà∞ {country} ÁöÑÂ§ßÂ≠¶ /\\n {country} „ÅÆÂ§ßÂ≠¶„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì / {country}Ïùò ÎåÄÌïôÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§ /\\n –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—ã {country} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã /\\n Aucune universit√© trouv√©e pour {country} / Keine Universit√§t in {country} gefunden /\\n No universities found in {country}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n{country.upper()} Ââç {n} ÂêçÂ§ßÂ≠∏ / Top {n} Universities in {country.upper()}:\")\n",
        "    for i, uni in enumerate(universities, 1):\n",
        "        print(f\"{i}. {uni}\")\n",
        "\n",
        "    search_keywords = [\n",
        "        \"summer research internship\", \"remote research assistant\", \"research scholarship\",\n",
        "    ]\n",
        "\n",
        "    print(\"\\nÊ≠£Âú®‰ΩøÁî® Google ÊêúÂ∞ãÁ†îÁ©∂Ê©üÊúÉ / Ê≠£Âú®Áî®GoogleÊêúÁ¥¢Á†îÁ©∂Êú∫‰ºö /\\n Google„ÅßÁ†îÁ©∂Ê©ü‰ºö„ÇíÊ§úÁ¥¢‰∏≠ / GoogleÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ïó∞Íµ¨ Í∏∞Ìöå Í≤ÄÏÉâ Ï§ë /\\n –ò–¥—ë—Ç –ø–æ–∏—Å–∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤ Google /\\n Recherche d'opportunit√©s de recherche via Google / Recherche √ºber Google nach Forschungsangeboten /\\n Searching research opportunities using Google...\\n\")\n",
        "    for uni in universities:\n",
        "        print(f\"\\n{uni} ÁöÑÊêúÂ∞ãÁµêÊûú / Search results for {uni}:\")\n",
        "        for keyword in search_keywords:\n",
        "            query = f\"{uni} {keyword}\"\n",
        "            results = search_google(query)\n",
        "            for title, link in results:\n",
        "                print(f\"{title}\\n{link}\")\n",
        "\n",
        "    print(\"\\nÊêúÂ∞ã Reddit Ë≤ºÊñá‰∏≠ / Ê≠£Âú®ÊêúÁ¥¢Reddit /\\n Reddit„ÅÆÊäïÁ®ø„ÇíÊ§úÁ¥¢‰∏≠ / Reddit Í≤åÏãúÎ¨º Í≤ÄÏÉâ Ï§ë /\\n –ü–æ–∏—Å–∫ –ø–æ Reddit /\\n Recherche sur Reddit / Suche in Reddit /\\n Searching Reddit...\\n\")\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(search_reddit(universities, search_keywords))\n",
        "\n",
        "# ‚úÖ Start the search process\n",
        "university_query()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej_PefuhxNSN",
        "outputId": "cefb7292-0f6f-49a6-8b86-339221e18d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ë´ãÈÅ∏ÊìáÊü•Ë©¢È°ûÂûã / ËØ∑ÈÄâÊã©Êü•ËØ¢Á±ªÂûã /\n",
            " Á®ÆÈ°û„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ / Ï°∞Ìöå Ïú†Ìòï ÏÑ†ÌÉù /\n",
            " –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ /\n",
            " Choisissez le type de requ√™te / W√§hlen Sie den Abfragetyp /\n",
            " Please select the query type\n",
            "(1: QSÁ∂úÂêàÊéíÂêç World Ranking, 2: QSÁ§æÊúÉÁßëÂ≠∏ÊéíÂêç Social Science Ranking): 1\n",
            "Ë´ãËº∏ÂÖ•Ë¶ÅÊü•Ë©¢ÁöÑÂúãÂÆ∂ / ËæìÂÖ•ÂõΩÂÆ∂ /\n",
            " ÂõΩ„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ / Íµ≠Í∞ÄÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî /\n",
            " –í–≤–µ–¥–∏—Ç–µ —Å—Ç—Ä–∞–Ω—É /\n",
            " Entrez le pays / Geben Sie das Land ein /\n",
            " Enter the country\n",
            "‰æãÂ¶Ç e.g., USA„ÄÅUK„ÄÅRussia: usa\n",
            "Ë´ãËº∏ÂÖ•Ë©≤ÂúãÂâçÂπæÂêçÂ§ßÂ≠∏ / ËæìÂÖ•ËØ•ÂõΩÂâçNÂêçÂ§ßÂ≠¶ /\n",
            " ‰∏ä‰ΩçÊ†°„ÇíÂÖ•Âäõ / ÏÉÅÏúÑ ÎåÄÌïô Ïàò ÏûÖÎ†• /\n",
            " –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –ª—É—á—à–∏—Ö –≤—É–∑–æ–≤ /\n",
            " Entrez le nombre d'universit√©s / Geben Sie die Anzahl der Top-Unis ein /\n",
            " Enter the top N universities:\n",
            "Êï∏Â≠ó only number: 1\n",
            "\n",
            "USA Ââç 1 ÂêçÂ§ßÂ≠∏ / Top 1 Universities in USA:\n",
            "1. Massachusetts Institute of Technology (MIT) \n",
            "\n",
            "Ê≠£Âú®‰ΩøÁî® Google ÊêúÂ∞ãÁ†îÁ©∂Ê©üÊúÉ / Ê≠£Âú®Áî®GoogleÊêúÁ¥¢Á†îÁ©∂Êú∫‰ºö /\n",
            " Google„ÅßÁ†îÁ©∂Ê©ü‰ºö„ÇíÊ§úÁ¥¢‰∏≠ / GoogleÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ïó∞Íµ¨ Í∏∞Ìöå Í≤ÄÏÉâ Ï§ë /\n",
            " –ò–¥—ë—Ç –ø–æ–∏—Å–∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤ Google /\n",
            " Recherche d'opportunit√©s de recherche via Google / Recherche √ºber Google nach Forschungsangeboten /\n",
            " Searching research opportunities using Google...\n",
            "\n",
            "\n",
            "Massachusetts Institute of Technology (MIT)  ÁöÑÊêúÂ∞ãÁµêÊûú / Search results for Massachusetts Institute of Technology (MIT) :\n",
            "MIT Summer Research Program | MIT Office of Graduate Education\n",
            "https://oge.mit.edu/msrp/\n",
            "Summer Research Program | MIT Lincoln Laboratory\n",
            "https://www.ll.mit.edu/careers/student-opportunities/summer-research-program\n",
            "Summer research programs | Office of Graduate Education\n",
            "https://oge.mit.edu/graduate-admissions/applications/summer-research-programs/\n",
            "MIT UROP ‚Äì Undergraduate Research Opportunities Program\n",
            "https://urop.mit.edu/\n",
            "MITES Summer ‚Äì MITES\n",
            "https://mites.mit.edu/discover-mites/mites-summer/\n",
            "Jobs at MIT | MIT Human Resources\n",
            "https://hr.mit.edu/jobs\n",
            "Research Assistantships and Financial Support - Technology and ...\n",
            "https://tpp.mit.edu/academics/research-assistantships-and-financial-support/\n",
            "Departmental funding | MIT Student Financial Services\n",
            "https://sfs.mit.edu/graduate-students/funding-and-aid/departmental-funding/\n",
            "MIT UROP ‚Äì Undergraduate Research Opportunities Program\n",
            "https://urop.mit.edu/\n",
            "21 Mit Research Associate jobs in United States\n",
            "https://www.linkedin.com/jobs/mit-research-associate-jobs\n",
            "MIT Scholarships | MIT Student Financial Services\n",
            "https://sfs.mit.edu/undergraduate-students/types-of-aid/mit-scholarship/\n",
            "MIT Sea Grant: Home\n",
            "https://seagrant.mit.edu/\n",
            "Making MIT affordable | MIT Student Financial Services\n",
            "https://sfs.mit.edu/undergraduate-students/the-cost-of-attendance/making-mit-affordable/\n",
            "Massachusetts Institute of Technology - Wikipedia\n",
            "https://en.wikipedia.org/wiki/Massachusetts_Institute_of_Technology\n",
            "MIT THINK Scholars Program: Home\n",
            "https://think.mit.edu/\n",
            "\n",
            "ÊêúÂ∞ã Reddit Ë≤ºÊñá‰∏≠ / Ê≠£Âú®ÊêúÁ¥¢Reddit /\n",
            " Reddit„ÅÆÊäïÁ®ø„ÇíÊ§úÁ¥¢‰∏≠ / Reddit Í≤åÏãúÎ¨º Í≤ÄÏÉâ Ï§ë /\n",
            " –ü–æ–∏—Å–∫ –ø–æ Reddit /\n",
            " Recherche sur Reddit / Suche in Reddit /\n",
            " Searching Reddit...\n",
            "\n",
            "\n",
            "„ÄêSearching Reddit posts„Äë\n",
            "\n",
            "\n",
            "Ôºö\"Massachusetts Institute of Technology (MIT) \" summer research internship\n",
            "\n",
            "Ôºö\"Massachusetts Institute of Technology (MIT) \" remote research assistant\n",
            "\n",
            "Ôºö\"Massachusetts Institute of Technology (MIT) \" research scholarship\n",
            "Title: I'm 15 and I'm planning to study in the us and I need guidance\n",
            "Date: 2024-12-13\n",
            "Link: https://www.reddit.com/r/ApplyingToCollege/comments/1hd6joa/im_15_and_im_planning_to_study_in_the_us_and_i/\n",
            "Subreddit: r/ApplyingToCollege\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hDNxGqOXydsD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}